{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "#!conda install tensorflow\r\n",
    "#!conda install pytorch\r\n",
    "#!conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c conda-forge\r\n",
    "#!pip install pytorch-lightning\r\n",
    "#!pip install datasets\r\n",
    "#!pip install transformers\r\n",
    "#!conda install keras\r\n",
    "#!pip install wandb\r\n",
    "#!pip install sklearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "from datasets import list_datasets\r\n",
    "datasets_list = list_datasets()\r\n",
    "len(datasets_list)\r\n",
    "print(', '.join(dataset for dataset in datasets_list))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acronym_identification, ade_corpus_v2, adversarial_qa, aeslc, afrikaans_ner_corpus, ag_news, ai2_arc, air_dialogue, ajgt_twitter_ar, allegro_reviews, allocine, alt, amazon_polarity, amazon_reviews_multi, amazon_us_reviews, ambig_qa, ami, amttl, anli, app_reviews, aqua_rat, aquamuse, ar_cov19, ar_res_reviews, ar_sarcasm, arabic_billion_words, arabic_pos_dialect, arabic_speech_corpus, arcd, arsentd_lev, art, arxiv_dataset, ascent_kb, aslg_pc12, asnq, asset, assin, assin2, atomic, autshumato, babi_qa, banking77, bbaw_egyptian, bbc_hindi_nli, bc2gm_corpus, beans, best2009, bianet, bible_para, big_patent, billsum, bing_coronavirus_query_set, biomrc, biosses, blended_skill_talk, blimp, blog_authorship_corpus, bn_hate_speech, bookcorpus, bookcorpusopen, boolq, bprec, break_data, brwac, bsd_ja_en, bswac, c3, c4, cail2018, caner, capes, casino, catalonia_independence, cats_vs_dogs, cawac, cbt, cc100, cc_news, ccaligned_multilingual, cdsc, cdt, cedr, cfq, chr_en, cifar10, cifar100, circa, civil_comments, clickbait_news_bg, climate_fever, clinc_oos, clue, cmrc2018, cnn_dailymail, coached_conv_pref, coarse_discourse, codah, code_search_net, code_x_glue_cc_clone_detection_big_clone_bench, code_x_glue_cc_clone_detection_poj104, code_x_glue_cc_cloze_testing_all, code_x_glue_cc_cloze_testing_maxmin, code_x_glue_cc_code_completion_line, code_x_glue_cc_code_completion_token, code_x_glue_cc_code_refinement, code_x_glue_cc_code_to_code_trans, code_x_glue_cc_defect_detection, code_x_glue_ct_code_to_text, code_x_glue_tc_nl_code_search_adv, code_x_glue_tc_text_to_code, code_x_glue_tt_text_to_text, com_qa, common_gen, common_voice, commonsense_qa, competition_math, compguesswhat, conceptnet5, conll2000, conll2002, conll2003, conllpp, conv_ai, conv_ai_2, conv_ai_3, conv_questions, coqa, cord19, cornell_movie_dialog, cos_e, cosmos_qa, counter, covid_qa_castorini, covid_qa_deepset, covid_qa_ucsd, covid_tweets_japanese, covost2, craigslist_bargains, crawl_domain, crd3, crime_and_punish, crows_pairs, cryptonite, cs_restaurants, cuad, curiosity_dialogs, daily_dialog, dane, danish_political_comments, dart, datacommons_factcheck, dbpedia_14, dbrd, deal_or_no_dialog, definite_pronoun_resolution, dengue_filipino, dialog_re, diplomacy_detection, disaster_response_messages, discofuse, discovery, disfl_qa, doc2dial, docred, doqa, dream, drop, duorc, dutch_social, dyk, e2e_nlg, e2e_nlg_cleaned, ecb, ecthr_cases, eduge, ehealth_kd, eitb_parcc, eli5, emea, emo, emotion, emotone_ar, empathetic_dialogues, enriched_web_nlg, eraser_multi_rc, esnli, eth_py150_open, ethos, eu_regulatory_ir, eurlex, euronews, europa_eac_tm, europa_ecdc_tm, europarl_bilingual, event2Mind, evidence_infer_treatment, exams, factckbr, fake_news_english, fake_news_filipino, farsi_news, fashion_mnist, fever, few_rel, financial_phrasebank, finer, flores, flue, food101, fquad, freebase_qa, gap, gem, generated_reviews_enth, generics_kb, german_legal_entity_recognition, germaner, germeval_14, giga_fren, gigaword, glucose, glue, gnad10, go_emotions, gooaq, google_wellformed_query, grail_qa, great_code, guardian_authorship, gutenberg_time, hans, hansards, hard, harem, has_part, hate_offensive, hate_speech18, hate_speech_filipino, hate_speech_offensive, hate_speech_pl, hate_speech_portuguese, hatexplain, hausa_voa_ner, hausa_voa_topics, hda_nli_hindi, head_qa, health_fact, hebrew_projectbenyehuda, hebrew_sentiment, hebrew_this_world, hellaswag, hendrycks_test, hind_encorp, hindi_discourse, hippocorpus, hkcancor, hlgd, hope_edi, hotpot_qa, hover, hrenwac_para, hrwac, humicroedit, hybrid_qa, hyperpartisan_news_detection, iapp_wiki_qa_squad, id_clickbait, id_liputan6, id_nergrit_corpus, id_newspapers_2018, id_panl_bppt, id_puisi, igbo_english_machine_translation, igbo_monolingual, igbo_ner, ilist, imdb, imdb_urdu_reviews, imppres, indic_glue, indonlu, inquisitive_qg, interpress_news_category_tr, interpress_news_category_tr_lite, irc_disentangle, isixhosa_ner_corpus, isizulu_ner_corpus, iwslt2017, jeopardy, jfleg, jigsaw_toxicity_pred, jigsaw_unintended_bias, jnlpba, journalists_questions, kannada_news, kd_conv, kde4, kelm, kilt_tasks, kilt_wikipedia, kinnews_kirnews, klue, kor_3i4k, kor_hate, kor_ner, kor_nli, kor_nlu, kor_qpair, kor_sae, kor_sarcasm, labr, lama, lambada, large_spanish_corpus, laroseda, lc_quad, lener_br, liar, librispeech_asr, librispeech_lm, limit, lince, linnaeus, liveqa, lj_speech, lm1b, lst20, m_lama, mac_morpho, makhzan, masakhaner, math_dataset, math_qa, matinf, mbpp, mc4, mc_taco, md_gender_bias, mdd, med_hop, medal, medical_dialog, medical_questions_pairs, menyo20k_mt, meta_woz, metooma, metrec, miam, mkb, mkqa, mlqa, mlsum, mnist, mocha, moroco, movie_rationales, mrqa, ms_marco, ms_terms, msr_genomics_kbcomp, msr_sqa, msr_text_compression, msr_zhen_translation_parity, msra_ner, mt_eng_vietnamese, muchocine, multi_booked, multi_eurlex, multi_news, multi_nli, multi_nli_mismatch, multi_para_crawl, multi_re_qa, multi_woz_v22, multi_x_science_sum, mutual_friends, mwsc, myanmar_news, narrativeqa, narrativeqa_manual, natural_questions, ncbi_disease, nchlt, ncslgr, nell, neural_code_search, news_commentary, newsgroup, newsph, newsph_nli, newspop, newsqa, newsroom, nkjp-ner, nli_tr, nlu_evaluation_data, norec, norne, norwegian_ner, nq_open, nsmc, numer_sense, numeric_fused_head, oclar, offcombr, offenseval2020_tr, offenseval_dravidian, ofis_publik, ohsumed, ollie, omp, onestop_english, open_subtitles, openai_humaneval, openbookqa, openslr, openwebtext, opinosis, opus100, opus_books, opus_dgt, opus_dogc, opus_elhuyar, opus_euconst, opus_finlex, opus_fiskmo, opus_gnome, opus_infopankki, opus_memat, opus_montenegrinsubs, opus_openoffice, opus_paracrawl, opus_rf, opus_tedtalks, opus_ubuntu, opus_wikipedia, opus_xhosanavy, orange_sum, oscar, para_crawl, para_pat, parsinlu_reading_comprehension, paws, paws-x, pec, peer_read, peoples_daily_ner, per_sent, persian_ner, pg19, php, piaf, pib, piqa, pn_summary, poem_sentiment, polemo2, poleval2019_cyberbullying, poleval2019_mt, polsum, polyglot_ner, prachathai67k, pragmeval, proto_qa, psc, ptb_text_only, pubmed, pubmed_qa, py_ast, qa4mre, qa_srl, qa_zre, qangaroo, qanta, qasc, qasper, qed, qed_amara, quac, quail, quarel, quartz, quora, quoref, race, re_dial, reasoning_bg, recipe_nlg, reclor, reddit, reddit_tifu, refresd, reuters21578, ro_sent, ro_sts, ro_sts_parallel, roman_urdu, ronec, ropes, rotten_tomatoes, russian_super_glue, s2orc, samsum, sanskrit_classic, saudinewsnet, scan, scb_mt_enth_2020, schema_guided_dstc8, scicite, scielo, scientific_papers, scifact, sciq, scitail, scitldr, search_qa, sede, selqa, sem_eval_2010_task_8, sem_eval_2014_task_1, sem_eval_2018_task_1, sem_eval_2020_task_11, sent_comp, senti_lex, senti_ws, sentiment140, sepedi_ner, sesotho_ner_corpus, setimes, setswana_ner_corpus, sharc, sharc_modified, sick, silicone, simple_questions_v2, siswati_ner_corpus, smartdata, sms_spam, snips_built_in_intents, snli, snow_simplified_japanese_corpus, so_stacksample, social_bias_frames, social_i_qa, sofc_materials_articles, sogou_news, spanish_billion_words, spc, species_800, spider, squad, squad_adversarial, squad_es, squad_it, squad_kor_v1, squad_kor_v2, squad_v1_pt, squad_v2, squadshifts, srwac, sst, stereoset, stsb_mt_sv, stsb_multi_mt, style_change_detection, subjqa, super_glue, superb, swag, swahili, swahili_news, swda, swedish_ner_corpus, swedish_reviews, tab_fact, tamilmixsentiment, tanzil, tapaco, tashkeela, taskmaster1, taskmaster2, taskmaster3, tatoeba, ted_hrlr, ted_iwlst2013, ted_multi, ted_talks_iwslt, telugu_books, telugu_news, tep_en_fa_para, thai_toxicity_tweet, thainer, thaiqa_squad, thaisum, the_pile_books3, the_pile_openwebtext2, the_pile_stack_exchange, tilde_model, time_dial, times_of_india_news_headlines, timit_asr, tiny_shakespeare, tlc, tmu_gfm_dataset, totto, trec, trivia_qa, tsac, ttc4900, tunizi, tuple_ie, turk, turkish_movie_sentiment, turkish_ner, turkish_product_reviews, turkish_shrinked_ner, turku_ner_corpus, tweet_eval, tweet_qa, tweets_ar_en_parallel, tweets_hate_speech_detection, twi_text_c3, twi_wordsim353, tydiqa, ubuntu_dialogs_corpus, udhr, um005, un_ga, un_multi, un_pc, universal_dependencies, universal_morphologies, urdu_fake_news, urdu_sentiment_corpus, vivos, web_nlg, web_of_science, web_questions, weibo_ner, wi_locness, wiki40b, wiki_asp, wiki_atomic_edits, wiki_auto, wiki_bio, wiki_dpr, wiki_hop, wiki_lingua, wiki_movies, wiki_qa, wiki_qa_ar, wiki_snippets, wiki_source, wiki_split, wiki_summary, wikiann, wikicorpus, wikihow, wikipedia, wikisql, wikitext, wikitext_tl39, wili_2018, wino_bias, winograd_wsc, winogrande, wiqa, wisesight1000, wisesight_sentiment, wmt14, wmt15, wmt16, wmt17, wmt18, wmt19, wmt20_mlqe_task1, wmt20_mlqe_task2, wmt20_mlqe_task3, wmt_t2t, wnut_17, wongnai_reviews, woz_dialogue, wrbsc, x_stance, xcopa, xed_en_fi, xglue, xnli, xor_tydi_qa, xquad, xquad_r, xsum, xsum_factuality, xtreme, yahoo_answers_qa, yahoo_answers_topics, yelp_polarity, yelp_review_full, yoruba_bbc_topics, yoruba_gv_ner, yoruba_text_c3, yoruba_wordsim353, youtube_caption_corrections, zest, AConsApart/anime_subtitles_DialoGPT, Abdo1Kamr/Arabic_Hadith, AdWeeb/DravidianMT, Adnan/Urdu_News_Headlines, Akshith/aa, Akshith/g_rock, Akshith/test, Annielytics/DoctorsNotes, Avishekavi/Avi, BSC-TeMU/SQAC, BSC-TeMU/ancora-ca-ner, BSC-TeMU/sts-ca, BSC-TeMU/tecla, BSC-TeMU/viquiquad, BSC-TeMU/xquad-ca, Binbin/my_dataset, Bosio/pacman, Bosio/pacman_descriptions, CAGER/rick, CShorten/KerasBERT, CShorten/ZillowPrize, ChadxxxxHall/Inter-vision, Check/a_re_gi, Check/region_1, Check/region_2, Check/region_3, Check/region_4, Check/region_5, Check/region_6, Check/region_7, Check/region_8, Check/region_9, Check/regions, Check/vverify, Chun/dataset, Cropinky/flatearther, Cropinky/rap_lyrics_english, Cropinky/wow_fishing_bobber, Cyberfish/pos_tagger, Cyberfish/text_error_correction, Darren/data, Davlan/masakhanerV1, EMBO/biolang, EMBO/sd-nlp, ESZER/H, Emon/sobuj, Enes3774/data, Eymen3455/xsum_tr, FRTNX/cosuju, FRTNX/worldbank-projects, Felix-ML/quoteli3, Firoj/CrisisBench, Francois/futures_es, Fraser/mnist-text-default, Fraser/mnist-text-no-spaces, Fraser/mnist-text-small, Fraser/news-category-dataset, Fraser/python-lines, Fraser/short-jokes, Fraser/wiki_sentences, Gabriel/squad_v2_sv, GalacticAI/Noirset, Gauravadlakha1509/new_one, Gwangho/NCBI-Sars-Cov-2, HUPD/hupd-test, Halilyesilceng/autonlp-data-nameEntityRecognition, HarleyQ/WitcherDialogue, Harveenchadha/bol-models, HarveyBWest/mybot, Hellisotherpeople/DebateSum, Husain/intent-classification-en-fr, IlyaGusev/gazeta, IlyaGusev/headline_cause, Jean-Baptiste/wikiner_fr, Jikiwa/demo1, Jikiwa/demo2, Jikiwa/demo3, Jikiwa/demo4, Jikiwa/stargazers, Jikiwa/temp-repo-valid, KETI-AIR/aihub, KETI-AIR/klue, KETI-AIR/kor_corpora, KETI-AIR/korquad, KETI-AIR/nikl, Khanoooo/autonlp-data-Corona, LIAMF-USP/arc-retrieval-c4, LeoCordoba/CC-NEWS-ES-titles, LeoCordoba/CC-NEWS-ES, MBAH/MOVIESON, MKK/Dhivehi-English, MarianaSahagun/test, Mateo/testdataset, Melinoe/TheLabTexts, MickyMike/large_c_corpus, Mrleo1nid/Test_ru_dataset, Mulin/my_second_dataset, Mulin/my_third_dataset, NTUYG/RAGTest, Narsil/asr_dummy, Narsil/conversational_dummy, Narsil/image_dummy, NbAiLab/norec_agg, NbAiLab/norne, NbAiLab/norwegian_parliament, NbAiLab/test_corpus, Ofrit/tmp, Pengfei/test, Pongsaky/Wiki_SCG, Pyke/patent_abstract, QA/abk-eng, Remesita/tagged_reviews, RohanAiLab/persian_blog, RohanAiLab/persian_daily_news, RohanAiLab/persian_news_dataset, SCourthial/test, SajjadAyoubi/persian_qa, Sam2021/Arguement_Mining_CL2017, SaulLu/Natural_Questions_HTML, SaulLu/Natural_Questions_HTML_Toy, SaulLu/Natural_Questions_HTML_reduced_all, SaulLu/test, SaulLu/toy_struc_dataset, Serhii/Custom_SQuAD, SoLID/shellcode_i_a32, SocialGrep/reddit-crypto-aug-2021, SocialGrep/reddit-nonewnormal-complete, SocialGrep/reddit-wallstreetbets-aug-2021, TRoboto/masc, Tatyana/ru_sentiment_dataset, Terry0107/RiSAWOZ, Tevatron/msmarco-passage-corpus, Tevatron/msmarco-passage, Tevatron/scifact-corpus, Tevatron/scifact, Tevatron/wikipedia-curated-corpus, Tevatron/wikipedia-curated, Tevatron/wikipedia-nq-corpus, Tevatron/wikipedia-nq, Tevatron/wikipedia-squad-corpus, Tevatron/wikipedia-squad, Tevatron/wikipedia-trivia-corpus, Tevatron/wikipedia-trivia, Tevatron/wikipedia-wq-corpus, Tevatron/wikipedia-wq, TheBlindBandit/SpongeNot, TimTreasure4/Test, Trainmaster9977/957, Trainmaster9977/zbakuman, Tyler/wikimatrix_collapsed, Valahaar/wsdmt, Vishva/UniFAQ_DataSET, VoVanPhuc/translate_vi2en, Wikidepia/IndoParaCrawl, Wikidepia/IndoSQuAD, Wikidepia/mc4-filter, WyrdCurt/AO4W, XiangPan/snli_break, XiangXiang/clt, Yves/fhnw_swiss_parliament, aapot/mc4_fi_cleaned, abhishek/autonlp-data-imdb_eval, abwicke/C-B-R, abwicke/koplo, adamlin/FewShotWoz, adamlin/companion, adamlin/daily_dialog, adamlin/domain_classification, adamlin/multiwoz_dst, adamlin/qa_verification, adamlin/roc_story, adamlin/rs, adamlin/weibo_ner, ajmbell/test-dataset, albertvillanova/datasets-tests-compression, albertvillanova/dummy_libri2mix, albertvillanova/tests-public-raw-jsonl, albertvillanova/tests-raw-jsonl, alireza655/alireza655, allegro/polish-question-passage-pairs, allegro/summarization-allegro-articles, allegro/summarization-polish-summaries-corpus, allenai/c4, allenai/scico, anton-l/common_language, anton-l/superb_demo, anton-l/superb_dummy, anukaver/EstQA, artyeth/Dorian, ashish-shrivastava/dont-know-dataset, asi/wikitext_fr, astarostap/antisemitic-tweets, astarostap/antisemitic_tweets, atelders/politweets, athivvat/thai-rap-lyrics, ausgequetschtem/jtrddfhfgh, bavard/personachat_truecased, bemanningssitua/dplremjfjfj, berkergurcay/2020-10K-Reports, bertin-project/mc4-es-sampled, bertin-project/mc4-sampling, bhadresh-savani/web_split, bigscience/mc4-sampled, bigscience/open_subtitles_monolingual, blinoff/medical_qa_ru_data, braincode/braincode, bs-modeling-metadata/OSCAR_Entity_13_000, bs-modeling-metadata/c4_newslike_url_only, bs-modeling-metadata/website_metadata_c4, bsc/ancora-ca-ner, bsc/sts-ca, bsc/tecla, bsc/viquiquad, bsc/xquad-ca, caca/zscczs, cakiki/args_me, canwenxu/dogwhistle, castorini/mr-tydi-corpus, castorini/mr-tydi, ccccccc/hdjw_94ejrjr, cdleong/piglatin-mt, cdminix/iwslt2011, cdminix/mgb1, cemigo/taylor_vs_shakes, cemigo/test-data, chenyuxuan/wikigold, cheulyop/ksponspeech, clarin-pl/cst-wikinews, clarin-pl/kpwr-ner, clarin-pl/nkjp-pos, clarin-pl/polemo2-official, classla/copa_hr, classla/hr500k, classla/reldi_hr, classla/reldi_sr, classla/setimes_sr, clem/autonlp-data-french_word_detection, clips/mfaq, cnrcastroli/aaaa, coala/kkk, congpt/dstc23_asr, corypaik/prost, csebuetnlp/xlsum, csebuetnlp/xnli_bn, ctl/ConceptualCaptions, dasago78/dasago78dataset, dataset/wikipedia_bn, david-wb/zeshel, deepset/germandpr, deepset/germanquad, dfgvhxfgv/fghghj, dfki-nlp/few-nerd, dgao/librispeech_nc_test, dgknrsln/Yorumsepeti, diiogo/brwac-clean, dispenst/jhghdghfd, dispix/test-dataset, dk-crazydiv/huggingface-modelhub, dongpil/test, dumitrescustefan/ronec, dvilasuero/ag_news_training_set_losses, dynabench/dynasent, dynabench/qa, eason929/test, edfews/szdfcszdf, edsas/fgrdtgrdtdr, edsas/grttyi, ehcalabres/ravdess_speech, ervis/aaa, ervis/qqq, eugenesiow/BSD100, eugenesiow/Div2k, eugenesiow/PIRM, eugenesiow/Set14, eugenesiow/Set5, eugenesiow/Urban100, ewdrtfwe/54refyghrtf, fatvvs/autonlp-data-entity_model_conll2003, fihtrotuld/asu, flax-community/code_clippy_data, flax-community/conceptual-12m-mbart-50-multilingual, flax-community/conceptual-12m-multilingual-marian-128, flax-community/conceptual-12m-multilingual-marian-es, flax-community/conceptual-12m-multilingual-marian, flax-community/conceptual-captions-12, flax-community/dummy-oscar-als-32, flax-community/german-common-voice-processed, flax-community/german_common_crawl, flax-community/multilingual-vqa, flax-community/norwegian-clean-dummy, flax-community/swahili-safi, flax-sentence-embeddings/Gender_Bias_Evaluation_Set, flax-sentence-embeddings/paws-jsonl, flax-sentence-embeddings/stackexchange_math_jsonl, flax-sentence-embeddings/stackexchange_title_best_voted_answer_jsonl, flax-sentence-embeddings/stackexchange_title_body_jsonl, flax-sentence-embeddings/stackexchange_titlebody_best_and_down_voted_answer_jsonl, flax-sentence-embeddings/stackexchange_titlebody_best_voted_answer_jsonl, flax-sentence-embeddings/stackexchange_xml, formermagic/github_python_1m, formu/CVT, fulai/DuReader, fuliucansheng/data_for_test, fuliucansheng/minicoco, fuliucansheng/mininlp, fuliucansheng/pascal_voc, fuyun1107/clip-for-vlp, fvillena/cantemist, fvillena/spanish_diagnostics, gar1t/test, german-nlp-group/german_common_crawl, gmnlp/tico19, gpt3mix/rt20, gpt3mix/sst2, greeneggsandyaml/test-dataset-debug, gsarti/change_it, gsarti/clean_mc4_it, gustavecortal/fr_covid_news, habu24/fdz, hakurei/touhou-dataset, hartzeer/kdfjdshfje, hf-internal-testing/cats_vs_dogs_sample, hf-internal-testing/fixtures_docvqa, hfface/poopi, holodata/sensai, howardmiddleton382/esuyertusutr, howardmiddleton382/wgweagwege, huggingFaceUser02/air21_grp13_inference_results, huggingFaceUser02/air21_grp13_tokenized_results, huggingartists/21-savage, huggingartists/25-17, huggingartists/50-cent, huggingartists/5nizza, huggingartists/5opka, huggingartists/aaron-watson, huggingartists/abba, huggingartists/adele, huggingartists/agata-christie, huggingartists/aikko, huggingartists/aimer, huggingartists/ajr, huggingartists/alan-walker, huggingartists/arash, huggingartists/arctic-monkeys, huggingartists/ariana-grande, huggingartists/armin-van-buuren, huggingartists/asdfgfa, huggingartists/asper-x, huggingartists/baklan, huggingartists/big-baby-tape, huggingartists/big-russian-boss, huggingartists/bill-wurtz, huggingartists/billie-eilish, huggingartists/billy-talent, huggingartists/boris-grebenshikov, huggingartists/braii, huggingartists/bruce-springsteen, huggingartists/burzum, huggingartists/cardi-b, huggingartists/chester-bennington, huggingartists/cocomelon, huggingartists/coin, huggingartists/coldplay, huggingartists/dababy, huggingartists/david-bowie, huggingartists/ddt, huggingartists/deep-purple, huggingartists/denderty, huggingartists/dermot-kennedy, huggingartists/dj-artem-artemov, huggingartists/doja-cat, huggingartists/drake, huggingartists/dua-lipa, huggingartists/duran-duran, huggingartists/dzhizus, huggingartists/ed-sheeran, huggingartists/egor-kreed, huggingartists/egor-letov, huggingartists/elton-john, huggingartists/eminem, huggingartists/enigma, huggingartists/enya, huggingartists/epic-rap-battles-of-history, huggingartists/face, huggingartists/fascinoma, huggingartists/fear-factory, huggingartists/florence-the-machine, huggingartists/freelancer, huggingartists/galenskaparna-and-after-shave, huggingartists/ghost, huggingartists/ghostemane, huggingartists/ghostmane, huggingartists/gorillaz, huggingartists/green-day, huggingartists/grigory-leps, huggingartists/grimes, huggingartists/gspd, huggingartists/gunna, huggingartists/hillsong-worship, huggingartists/i-dont-know-how-but-they-found-me, huggingartists/idktime, huggingartists/imagine-dragons, huggingartists/jah-khalib, huggingartists/jim-morrison, huggingartists/john-lennon, huggingartists/joji, huggingartists/joni-mitchell, huggingartists/justin-bieber, huggingartists/kanye-west, huggingartists/kasta, huggingartists/kehlani, huggingartists/king-krule, huggingartists/kipelov, huggingartists/kishlak, huggingartists/kizaru, huggingartists/krechet, huggingartists/krept-and-konan-bugzy-malone-sl-morisson-abra-cadabra-rv-and-snap-capone, huggingartists/lady-gaga, huggingartists/lazy-jay, huggingartists/led-zeppelin, huggingartists/lil-baby, huggingartists/lil-nas-x, huggingartists/lil-peep, huggingartists/lil-skies, huggingartists/lil-uzi-vert, huggingartists/linkin-park, huggingartists/little-big, huggingartists/lizer, huggingartists/logic, huggingartists/lorde, huggingartists/loud-luxury, huggingartists/loverance, huggingartists/lovv66, huggingartists/lumen, huggingartists/lyapis-trubetskoy, huggingartists/macan, huggingartists/machine-gun-kelly, huggingartists/madonna, huggingartists/maroon-5, huggingartists/mashina-vremeni, huggingartists/mating-ritual, huggingartists/max-korzh, huggingartists/mayot, huggingartists/melanie-martinez, huggingartists/mf-doom, huggingartists/michael-jackson, huggingartists/mikhail-gorshenev, huggingartists/miyagi, huggingartists/mnogoznaal, huggingartists/morgenshtern, huggingartists/mumiy-troll, huggingartists/muse, huggingartists/nervy, huggingartists/nirvana, huggingartists/noize-mc, huggingartists/obladaet, huggingartists/og-buda, huggingartists/ot-rus, huggingartists/our-last-night, huggingartists/oxxxymiron, huggingartists/peter-paul-and-mary, huggingartists/pharaoh, huggingartists/placebo, huggingartists/platina, huggingartists/pop-smoke, huggingartists/post-malone, huggingartists/pyrokinesis, huggingartists/queen, huggingartists/radiohead, huggingartists/rage-against-the-machine, huggingartists/red-hot-chili-peppers, huggingartists/rex-orange-county, huggingartists/rihanna, huggingartists/rocket, huggingartists/sam-kim, huggingartists/scriptonite, huggingartists/sektor-gaza, huggingartists/sergei-letov, huggingartists/sia, huggingartists/sid-sriram, huggingartists/skillet, huggingartists/slava-kpss, huggingartists/slava-marlow, huggingartists/snoop-dogg, huggingartists/sugar-ray, huggingartists/suicideoscope, huggingartists/sundara-karma, huggingartists/system-of-a-down, huggingartists/tanzy-minus, huggingartists/taylor-swift, huggingartists/the-69-eyes, huggingartists/the-avalanches, huggingartists/the-beatles, huggingartists/the-gazette, huggingartists/the-king-and-the-jester, huggingartists/the-the-pigs, huggingartists/the-velvet-underground, huggingartists/the-weeknd, huggingartists/tiamat, huggingartists/till-lindemann, huggingartists/tom-waits, huggingartists/tony-raut-and-garry-topor, huggingartists/tool, huggingartists/totpoc, huggingartists/travis-scott, huggingartists/twenty-one-pilots, huggingartists/upsahl, huggingartists/v-x-v-prince, huggingartists/van-morrison, huggingartists/veggietales, huggingartists/viktor-tsoi, huggingartists/vladimir-vysotsky, huggingartists/xxxtentacion, huggingartists/young-thug, huggingartists/yung-plague, huggingartists/zemfira, huggingface/label-files, huggingface-course/codeparrot-ds-train, huggingface-course/codeparrot-ds-valid, iamshsdf/sssssssssss, iarfmoose/question_generator, imthanhlv/binhvq_dedup, imthanhlv/binhvq_news21_raw, indonesian-nlp/id_personachat, jaimin/wav2vec2-large-xlsr-gujarati-demo, jakemarcus/MATH, jamol1741/test_dataset, jdepoix/junit_test_completion, jglaser/binding_affinity, jhqwqq/2, jimregan/clarinpl_sejmsenat, jimregan/clarinpl_studio, jinmang2/load_klue_re, jinmang2/tacred_example, jiyoojeong/targetizer, jmamou/augmented-glue-sst2, joelito/ler, joelito/sem_eval_2010_task_8, jonfd/ICC, julien-c/dummy-dataset-from-colab, julien-c/reactiongif, juny116/few_glue, k-halid/ar, k0t1k/test, kaka10/fgfgfgfg, karinev/lanuitdudroit, katoensp/VR-OP, keshan/clean-si-mc4, keshan/large-sinhala-asr-dataset, keshan/multispeaker-tts-sinhala, keshan/wit-dataset, kevinlu1248/personificationgen, khanbaba/online_love, kiamehr74/CoarseWSD-20, kleinay/qa_srl2018, kleinay/qanom, kmyoo/klue-tc-dev, knilakshan20/wikigold, laugustyniak/abusive-clauses-pl, lavis-nlp/german_legal_sentences, lbourdois/CoFiF, leoapolonio/AMI_Meeting_Corpus, lewtun/asr-preds-test, lewtun/asr_dummy, lewtun/binary_classification_dummy, lewtun/bulk-superb-s3p-superb-49606, lewtun/drug-reviews, lewtun/github-issues-test, lewtun/github-issues, lewtun/mnist-preds, lewtun/s3prl-sd-dummy, lewtun/text_classification_dummy, lhoestq/custom_squad, lhoestq/demo1, lhoestq/squad, lhoestq/test, lhoestq/test2, lhoestq/wikipedia_bn, liam168/nlp_c4_sentiment, lkiouiou/o9ui7877687, lkndsjkndgskjngkjsndkj/jsjdjsdvkjvszlhdskb, lohanna/testedjkcxkf, lorsorlah/Dadedadedam, loveguruji609/dfdfsdfsdfsdfsdfsd, lucien/sciencemission, lucien/voacantonesed, lucien/wsaderfffjjjhhh, lucio/common_voice_eval, lukasmasuch/my-test-repo-3, lukasmasuch/my-test-repo-4, lukasmasuch/test-2, lukasmasuch/test-3, lukasmasuch/test, luofengge/mydata, luofengge/testDataset, lvwerra/codeparrot-valid, m3hrdadfi/recipe_nlg_lite, mad/IndonesiaNewsDataset, maji/npo_mission_statement_ucf, majod/CleanNaturalQuestionsDataset, makanan/umich, manandey/OSCAR_Entity_Toy, markscrivo/OddsOn, martodaniel/terere, medzaf/test, merve/folk-mythology-tales, merve/poetry, metalearning/kaggale-nlp-tutorial, mhtoin/register_oscar, mksaad/Arabic_news, ml6team/cnn_dailymail_nl, mldmm/glass_alloy_composition, mmm-da/rutracker_anime_torrent_titles, mr-robot/ec, mrojas/abbreviation, mrojas/body, mrojas/disease, mrojas/family, mrojas/finding, mrojas/medication, mrojas/procedure, mulcyber/europarl-mono, munggok/mc4-id, mustafa12/db_ee, mustafa12/edaaaas, mustafa12/thors, nateraw/auto-cats-and-dogs, nateraw/auto-exp-2, nateraw/beans, nateraw/beans_old, nateraw/bulk-dummy, nateraw/cats-and-dogs, nateraw/cats_vs_dogs, nateraw/fairface, nateraw/filings-10k, nateraw/food101, nateraw/food101_old, nateraw/image-folder, nateraw/imagefolder, nateraw/imagenette, nateraw/img-demo, nateraw/rock_paper_scissors, nateraw/sync_food101, nateraw/test, nateraw/wit, naver-clova-conversation/klue-tc-dev-tsv, naver-clova-conversation/klue-tc-tsv, naver-clova-conversation-ul/klue-tc-dev, nbroad/few-nerd, ncoop57/rico_captions, neelalex/raft-predictions, nielsr/FUNSD_layoutlmv2, nielsr/XFUN, nielsr/funsd, nlpaueb/test, nlpufg/brwac-pt, nlpufg/brwac, nlpufg/oscar-pt, notional/notional-python, nucklehead/ht-voice-dataset, oelkrise/CRT, osanseviero/codeparrot-train, osanseviero/llama_test, osanseviero/test, ought/raft-submission, ought/raft, parivartanayurveda/Malesexproblemsayurvedictreatment, pasinit/scotus, pasinit/xlwic, patrickvonplaten/common_voice_processed_turkish, patrickvonplaten/librispeech_asr_dummy, patrickvonplaten/librispeech_local, patrickvonplaten/librispeech_local_dummy, patrickvonplaten/scientific_papers_dummy, pdesoyres/test, peixian/equity_evaluation_corpus, peixian/rtGender, pelican/test_100, pere/norwegian_colossal_corpus_v2_short100k, persiannlp/parsinlu_entailment, persiannlp/parsinlu_query_paraphrasing, persiannlp/parsinlu_reading_comprehension, persiannlp/parsinlu_sentiment, persiannlp/parsinlu_translation_en_fa, persiannlp/parsinlu_translation_fa_en, phonlab-tcd/cngv1, phonlab-tcd/corpuscrawler-ga, piEsposito/br-quad-2.0, piEsposito/br_quad_20, piEsposito/squad_20_ptbr, pierreant-p/jcvd-or-linkedin, princeton-nlp/datasets-for-simcse, priya3301/Graduation_admission, priya3301/tes, priya3301/test, proffttega/ILLUMINATI, proffttega/doc, proffttega/join_illuminati_to_become_rich, proffttega/persian_daily_news, pulmo/chest_xray, qfortier/instagram_ny, qwant/squad_fr, rahular/itihasa, rajeshradhakrishnan/malayalam_2020_wiki, rajeshradhakrishnan/malayalam_news, ramybaly/conll2012, ramybaly/nerd, ranpox/xfund, rays2pix/example, rays2pix/example_dataset, retiol/REGARDER, retiol/auf, retiol/celyfilm, retiol/regarderr, rewardsignal/reddit_writing_prompts, rom1504/laion400m, rony/soccer-dialogues, roskoN/dailydialog, roskoN/dstc8-reddit-corpus, s-myk/test, sagnikrayc/mctest, sagnikrayc/quasar, salesken/Paraphrase_category_detection, sanyu/aw, sanyu/er, sanyu/hh, sanyu/vb, sc2qa/sc2q_commoncrawl, sc2qa/sc2qa_commoncrawl, sdfufygvjh/fgghuviugviu, seamew/ChnSentiCorp, seamew/Hotel, seamew/THUCNews, seamew/THUCNewsText, seamew/THUCNewsTitle, seamew/Weibo, seanbethard/autonlp-data-summarization_model, sentence-transformers/embedding-training-data, sentence-transformers/msmarco-hard-negatives, sentence-transformers/parallel-sentences, sentence-transformers/reddit-title-body, seregadgl/test_set, sevbqewre/vebdesbdty, severo/autonlp-data-sentiment_detection-3c8bcd36, shahrukhx01/questions-vs-statements, shanya/website_metadata_c4_toy, sharejing/BiPaR, sijpapi/batch13, sijpapi/funsd, sijpapi/funsds, sileod/metaeval, sismetanin/rureviews, smallv0221/my-test, somaimanguyat/Genjer, somaimanguyat/Koboy, somaimanguyat/Movieonline2021, somaimanguyat/Salome, somaimanguyat/movie21, somaimanguyat/xiomay, spacemanidol/ms_marco_doc2query, spacemanidol/msmarco_passage_ranking, ssasaa/gghghgh, sshleifer/pseudo_bart_xsum, stas/c4-en-10k, stas/openwebtext-10k, stas/oscar-en-10k, stas/wmt14-en-de-pre-processed, stas/wmt16-en-ro-pre-processed, stevhliu/demo, stiel/skjdhjkasdhasjkd, subiksha/OwnDataset, superb/superb-data, susumu2357/squad_v2_sv, svalabs/all-nli-german-translation-wmt19, svalabs/ms-marco-german-translation-wmt19, tals/test, tanfiona/causenet_wiki, tarudesu/UIT-ViCTSD, tharindu/MOLD, thiemowa/argumentationreviewcorpus, thiemowa/empathyreviewcorpus, thomwolf/codeparrot-train, thomwolf/codeparrot-valid, thomwolf/codeparrot, thomwolf/github-dataset, thomwolf/github-python, thomwolf/very-good-dataset, thomwolf/very-test-dataset-2, thomwolf/very-test-dataset, tianxing1994/temp, toloka/CrowdSpeech, toloka/VoxDIY-RusNews, tommy19970714/common_voice, toriving/kosimcse, toriving/talktalk-sentiment-210713-multi-singleturn-custom-multiturn, transformersbook/codeparrot-train, transformersbook/codeparrot-valid, transformersbook/codeparrot, ttj/metadata_arxiv, turingbench/TuringBench, uasoyasser/rgfes, usc-isi/Wiki-Convert, uva-irlab/canard_quretec, uva-irlab/trec-cast-2019-multi-turn, vasudevgupta/amazon-ml-hack, vasudevgupta/bigbird-tokenized-natural-questions, vasudevgupta/data, vasudevgupta/gsoc-librispeech, vasudevgupta/natural-questions-validation, vasudevgupta/temperature-distribution-2d-plate, vasudevgupta/temperature-distribution-3d-cylinder, vblagoje/eli5, vblagoje/wikipedia_snippets_streamed, vctc92/sdsd, vctc92/test, versae/norwegian-t5-dataset-debug, versae/norwegian-t5-dataset-debug2, versae/norwegian-t5-dataset-debug3, vershasaxena91/datasets, vershasaxena91/squad_multitask, vesteinn/icelandic-ner-MIM-GOLD-NER, w-nicole/childes_data, w-nicole/childes_data_no_tags, w-nicole/childes_data_no_tags_, w-nicole/childes_data_with_tags, w-nicole/childes_data_with_tags_, w11wo/imdb-javanese, webek18735/ddvoacantonesed, webek18735/dhikhscook, webis/args_me, weijieliu/senteval_cn, wisdomify/story, wmt/europarl, wmt/news-commentary, wmt/uncorpus, wmt/wikititles, wmt/wmt10, wmt/wmt13, wmt/wmt14, wmt/wmt15, wmt/wmt16, wmt/wmt17, wmt/wmt18, wmt/wmt19, wzkariampuzha/EpiExtract4GARD, xiaj/ds_test, xiaj/test0919, yannobla/Sunshine, yluisfern/PBU, yo/devparty, erikacardenas300/Zillow_Economics_Dataset, ejjaffe/onion_headlines_2_sources, Verpeliculas/ver-venom-habra-matanza-2021-pelicula-completa-online, Zaid/quac_expanded, Zaid/coqa_expanded, ShinyQ/PPKM_Pemerintah, XiangPan/iflytek, pariajm/sharif_emotional_speech_dataset\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "from datasets import load_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "cola_dataset = load_dataset(\"glue\", \"cola\")\r\n",
    "print(cola_dataset)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Reusing dataset glue (C:\\Users\\jhseo\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 746.32it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "train_dataset = cola_dataset['train']\r\n",
    "print(train_dataset[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\", 'label': 1, 'idx': 0}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import pytorch_lightning as pl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "class DataModule(pl.LightningDataModule):\r\n",
    "    def __init__(self, model_name=\"google/bert_uncased_L-2_H-128_A-2\", batch_size=32):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\r\n",
    "\r\n",
    "    def prepare_data(self):\r\n",
    "        cola_dataset = load_dataset(\"glue\", \"cola\")\r\n",
    "        self.train_data = cola_dataset[\"train\"]\r\n",
    "        self.val_data = cola_dataset[\"validation\"]\r\n",
    "\r\n",
    "    def tokenize_data(self, example):\r\n",
    "        # processing the data\r\n",
    "        return self.tokenizer(\r\n",
    "            example[\"sentence\"],\r\n",
    "            truncation=True,\r\n",
    "            padding=\"max_length\",\r\n",
    "            max_length=256,\r\n",
    "        )\r\n",
    "\r\n",
    "    def setup(self, stage=None):\r\n",
    "        if stage == \"fit\" or stage is None:\r\n",
    "            self.train_data = self.train_data.map(self.tokenize_data, batched=True)\r\n",
    "            self.train_data.set_format(\r\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\r\n",
    "            )\r\n",
    "\r\n",
    "            self.val_data = self.val_data.map(self.tokenize_data, batched=True)\r\n",
    "            self.val_data.set_format(\r\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\r\n",
    "            )\r\n",
    "\r\n",
    "    def train_dataloader(self):\r\n",
    "        return torch.utils.data.DataLoader(\r\n",
    "            self.train_data, batch_size=self.batch_size, shuffle=True\r\n",
    "        )\r\n",
    "\r\n",
    "    def val_dataloader(self):\r\n",
    "        return torch.utils.data.DataLoader(\r\n",
    "            self.val_data, batch_size=self.batch_size, shuffle=False\r\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "class ColaModel(pl.LightningModule):\r\n",
    "    def __init__(self, model_name=\"google/bert_uncased_L-2_H-128_A-2\", lr=1e-2):\r\n",
    "        super(ColaModel, self).__init__()\r\n",
    "        self.save_hyperparameters()\r\n",
    "\r\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\r\n",
    "        self.W = nn.Linear(self.bert.config.hidden_size, 2)\r\n",
    "        self.num_classes = 2\r\n",
    "\r\n",
    "    def forward(self, input_ids, attention_mask):\r\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\r\n",
    "\r\n",
    "        h_cls = outputs.last_hidden_state[:, 0]\r\n",
    "        logits = self.W(h_cls)\r\n",
    "        return logits\r\n",
    "\r\n",
    "    def training_step(self, batch, batch_idx):\r\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\r\n",
    "        loss = F.cross_entropy(logits, batch[\"label\"])\r\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\r\n",
    "        return loss\r\n",
    "\r\n",
    "    def validation_step(self, batch, batch_idx):\r\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\r\n",
    "        loss = F.cross_entropy(logits, batch[\"label\"])\r\n",
    "        _, preds = torch.max(logits, dim=1)\r\n",
    "        val_acc = accuracy_score(preds.cpu(), batch[\"label\"].cpu())\r\n",
    "        val_acc = torch.tensor(val_acc)\r\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\r\n",
    "        self.log(\"val_acc\", val_acc, prog_bar=True)\r\n",
    "\r\n",
    "    def configure_optimizers(self):\r\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams[\"lr\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from transformers import AutoTokenizer, AutoModel\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "cola_data = DataModule()\r\n",
    "cola_model = ColaModel()\r\n",
    "\r\n",
    "checkpoint_callback = ModelCheckpoint(\r\n",
    "    dirpath=\"./models\", monitor=\"val_loss\", mode=\"min\"\r\n",
    ")\r\n",
    "\r\n",
    "early_stopping_callback = EarlyStopping(\r\n",
    "    monitor=\"val_loss\", patience=3, verbose=True, mode=\"min\"\r\n",
    ")\r\n",
    "\r\n",
    "trainer = pl.Trainer(\r\n",
    "    default_root_dir=\"logs\",\r\n",
    "    gpus=(1 if torch.cuda.is_available() else 0),\r\n",
    "    max_epochs=1,\r\n",
    "    fast_dev_run=False,\r\n",
    "    logger=pl.loggers.TensorBoardLogger(\"logs/\", name=\"cola\", version=1),\r\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\r\n",
    ")\r\n",
    "trainer.fit(cola_model, cola_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:446: UserWarning: Checkpoint directory ./models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Reusing dataset glue (C:\\Users\\jhseo\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 751.85it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 15.30ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 15.85ba/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type      | Params\n",
      "-----------------------------------\n",
      "0 | bert | BertModel | 4.4 M \n",
      "1 | W    | Linear    | 258   \n",
      "-----------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.545    Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                              "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0: 100%|██████████| 301/301 [00:09<00:00, 33.27it/s, loss=0.611, v_num=1, train_loss=0.475, val_loss=0.624, val_acc=0.691]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Metric val_loss improved. New best score: 0.624\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0: 100%|██████████| 301/301 [00:09<00:00, 32.57it/s, loss=0.611, v_num=1, train_loss=0.475, val_loss=0.624, val_acc=0.691]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "class ColaPredictor:\r\n",
    "    def __init__(self, model_path):\r\n",
    "        self.model_path = model_path\r\n",
    "        # loading the trained model\r\n",
    "        self.model = ColaModel.load_from_checkpoint(model_path)\r\n",
    "        # keep the model in eval mode\r\n",
    "        self.model.eval()\r\n",
    "        self.model.freeze()\r\n",
    "        self.processor = DataModule()\r\n",
    "        self.softmax = torch.nn.Softmax(dim=0)\r\n",
    "        self.lables = [\"unacceptable\", \"acceptable\"]\r\n",
    "\r\n",
    "    def predict(self, text):\r\n",
    "        # text => run time input\r\n",
    "        inference_sample = {\"sentence\": text}\r\n",
    "        # tokenizing the input\r\n",
    "        processed = self.processor.tokenize_data(inference_sample)\r\n",
    "        # predictions\r\n",
    "        logits = self.model(\r\n",
    "            torch.tensor([processed[\"input_ids\"]]),\r\n",
    "            torch.tensor([processed[\"attention_mask\"]]),\r\n",
    "        )\r\n",
    "        scores = self.softmax(logits[0]).tolist()\r\n",
    "        predictions = []\r\n",
    "        for score, label in zip(scores, self.lables):\r\n",
    "            predictions.append({\"label\": label, \"score\": score})\r\n",
    "        return predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "import wandb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\r\n",
    "wandb_logger = WandbLogger(project=\"MLOps Basics\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "trainer = pl.Trainer(\r\n",
    "        max_epochs=3,\r\n",
    "        logger=wandb_logger,\r\n",
    "        callbacks=[checkpoint_callback],\r\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1303: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "import torchmetrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "class ColaModel(pl.LightningModule):\r\n",
    "    def __init__(self, model_name=\"google/bert_uncased_L-2_H-128_A-2\", lr=3e-5):\r\n",
    "        self.train_accuracy_metric = torchmetrics.Accuracy()\r\n",
    "        self.val_accuracy_metric = torchmetrics.Accuracy()\r\n",
    "        self.f1_metric = torchmetrics.F1(num_classes=self.num_classes)\r\n",
    "        self.precision_macro_metric = torchmetrics.Precision(\r\n",
    "            average=\"macro\", num_classes=self.num_classes\r\n",
    "        )\r\n",
    "        self.recall_macro_metric = torchmetrics.Recall(\r\n",
    "            average=\"macro\", num_classes=self.num_classes\r\n",
    "        )\r\n",
    "        self.precision_micro_metric = torchmetrics.Precision(average=\"micro\")\r\n",
    "        self.recall_micro_metric = torchmetrics.Recall(average=\"micro\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "def training_step(self, batch, batch_idx):\r\n",
    "    outputs = self.forward(\r\n",
    "        batch[\"input_ids\"], batch[\"attention_mask\"], labels=batch[\"label\"]\r\n",
    "    )\r\n",
    "    # loss = F.cross_entropy(logits, batch[\"label\"])\r\n",
    "    preds = torch.argmax(outputs.logits, 1)\r\n",
    "    train_acc = self.train_accuracy_metric(preds, batch[\"label\"])\r\n",
    "    self.log(\"train/loss\", outputs.loss, prog_bar=True, on_epoch=True)\r\n",
    "    self.log(\"train/acc\", train_acc, prog_bar=True, on_epoch=True)\r\n",
    "    return outputs.loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "def validation_step(self, batch, batch_idx):\r\n",
    "    labels = batch[\"label\"]\r\n",
    "    outputs = self.forward(\r\n",
    "        batch[\"input_ids\"], batch[\"attention_mask\"], labels=batch[\"label\"]\r\n",
    "    )\r\n",
    "    preds = torch.argmax(outputs.logits, 1)\r\n",
    "\r\n",
    "    # Metrics\r\n",
    "    valid_acc = self.val_accuracy_metric(preds, labels)\r\n",
    "    precision_macro = self.precision_macro_metric(preds, labels)\r\n",
    "    recall_macro = self.recall_macro_metric(preds, labels)\r\n",
    "    precision_micro = self.precision_micro_metric(preds, labels)\r\n",
    "    recall_micro = self.recall_micro_metric(preds, labels)\r\n",
    "    f1 = self.f1_metric(preds, labels)\r\n",
    "\r\n",
    "    # Logging metrics\r\n",
    "    self.log(\"valid/loss\", outputs.loss, prog_bar=True, on_step=True)\r\n",
    "    self.log(\"valid/acc\", valid_acc, prog_bar=True)\r\n",
    "    self.log(\"valid/precision_macro\", precision_macro, prog_bar=True)\r\n",
    "    self.log(\"valid/recall_macro\", recall_macro, prog_bar=True)\r\n",
    "    self.log(\"valid/precision_micro\", precision_micro, prog_bar=True)\r\n",
    "    self.log(\"valid/recall_micro\", recall_micro, prog_bar=True)\r\n",
    "    self.log(\"valid/f1\", f1, prog_bar=True)\r\n",
    "    return {\"labels\": labels, \"logits\": outputs.logits}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "def validation_epoch_end(self, outputs):\r\n",
    "    labels = torch.cat([x[\"labels\"] for x in outputs])\r\n",
    "    logits = torch.cat([x[\"logits\"] for x in outputs])\r\n",
    "    preds = torch.argmax(logits, 1)\r\n",
    "\r\n",
    "    cm = confusion_matrix(labels.numpy(), preds.numpy())\r\n",
    "\r\n",
    "    #1\r\n",
    "    self.logger.experiment.log(\r\n",
    "    {\r\n",
    "        \"conf\": wandb.plot.confusion_matrix(\r\n",
    "            probs=logits.numpy(), y_true=labels.numpy()\r\n",
    "        )\r\n",
    "    })\r\n",
    "\r\n",
    "    #2\r\n",
    "    wandb.log({\"cm\": wandb.sklearn.plot_confusion_matrix(labels.numpy(), preds)})\r\n",
    "\r\n",
    "    #3\r\n",
    "    data = confusion_matrix(labels.numpy(), preds.numpy())\r\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(labels), index=np.unique(labels))\r\n",
    "    df_cm.index.name = \"Actual\"\r\n",
    "    df_cm.columns.name = \"Predicted\"\r\n",
    "    plt.figure(figsize=(10, 5))\r\n",
    "    plot = sns.heatmap(\r\n",
    "        df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}\r\n",
    "    )  # font size\r\n",
    "    self.logger.experiment.log({\"Confusion Matrix\": wandb.Image(plot)})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "class SamplesVisualisationLogger(pl.Callback):\r\n",
    "    def __init__(self, datamodule):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.datamodule = datamodule\r\n",
    "\r\n",
    "    def on_validation_end(self, trainer, pl_module):\r\n",
    "        # can be done on complete dataset also\r\n",
    "        val_batch = next(iter(self.datamodule.val_dataloader()))\r\n",
    "        sentences = val_batch[\"sentence\"]\r\n",
    "\r\n",
    "        # get the predictions\r\n",
    "        outputs = pl_module(val_batch[\"input_ids\"], val_batch[\"attention_mask\"])\r\n",
    "        preds = torch.argmax(outputs.logits, 1)\r\n",
    "        labels = val_batch[\"label\"]\r\n",
    "\r\n",
    "        # predicted and labelled data\r\n",
    "        df = pd.DataFrame(\r\n",
    "            {\"Sentence\": sentences, \"Label\": labels.numpy(), \"Predicted\": preds.numpy()}\r\n",
    "        )\r\n",
    "\r\n",
    "        # wrongly predicted data\r\n",
    "        wrong_df = df[df[\"Label\"] != df[\"Predicted\"]]\r\n",
    "\r\n",
    "        # Logging wrongly predicted dataframe as a table\r\n",
    "        trainer.logger.experiment.log(\r\n",
    "            {\r\n",
    "                \"examples\": wandb.Table(dataframe=wrong_df, allow_mixed_types=True),\r\n",
    "                \"global_step\": trainer.global_step,\r\n",
    "            }\r\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "trainer = pl.Trainer(\r\n",
    "        max_epochs=3,\r\n",
    "        logger=wandb_logger,\r\n",
    "        callbacks=[checkpoint_callback, SamplesVisualisationLogger(cola_data), early_stopping_callback],\r\n",
    "        log_every_n_steps=10,\r\n",
    "        deterministic=True,\r\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1303: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "import torch\r\n",
    "torch.cuda.is_available()\r\n",
    "torch.cuda.current_device()\r\n",
    "torch.cuda.device(0)\r\n",
    "torch.cuda.device_count()\r\n",
    "torch.cuda.get_device_name(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Laptop GPU'"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# setting device on GPU if available, else CPU\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "print('Using device:', device)\r\n",
    "print()\r\n",
    "\r\n",
    "#Additional Info when using cuda\r\n",
    "if device.type == 'cuda':\r\n",
    "    print(torch.cuda.get_device_name(0))\r\n",
    "    print('Memory Usage:')\r\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\r\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "trainer.fit(cola_model, cola_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name | Type      | Params\n",
      "-----------------------------------\n",
      "0 | bert | BertModel | 4.4 M \n",
      "1 | W    | Linear    | 258   \n",
      "-----------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.545    Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  5.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  5.24it/s]"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'sentence'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24124/814329373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcola_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcola_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader)\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresume_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[1;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m         \u001b[1;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    988\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"pl.Trainer\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"pl.Trainer\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"pl.Trainer\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;31m# double dispatch to initiate the training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"pl.Trainer\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1035\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[1;31m# enable train mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[1;34m(self, ref_model)\u001b[0m\n\u001b[0;32m   1120\u001b[0m             \u001b[1;31m# run eval step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\loops\\base.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_run_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py\u001b[0m in \u001b[0;36mon_run_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;31m# hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_evaluation_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;31m# save predictions to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py\u001b[0m in \u001b[0;36mon_evaluation_end\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_test_end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_validation_end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mTrainerFn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFITTING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mcall_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m                 \u001b[0mtrainer_hook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1228\u001b[1;33m                 \u001b[0mtrainer_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m             \u001b[1;31m# next call hook in lightningModule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlops\\lib\\site-packages\\pytorch_lightning\\trainer\\callback_hook.py\u001b[0m in \u001b[0;36mon_validation_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;34m\"\"\"Called when the validation loop ends.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_validation_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24124/2020241321.py\u001b[0m in \u001b[0;36mon_validation_end\u001b[1;34m(self, trainer, pl_module)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# can be done on complete dataset also\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mval_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sentence\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# get the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentence'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('mlops': conda)"
  },
  "interpreter": {
   "hash": "8e45873a4542e3cc3866bc5e6205c41a5b64d8a4fb25e1bd2147562e54ef506d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}